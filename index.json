[{"categories":null,"contents":" Rsync $ rsync -avzhe \u0026#39;ssh -p [port_number]\u0026#39; -P [user@remote_ip]:/path/to/file/source /path/to/file/destination Scan IP on Network $ nmap -sP [ip_address/prefix] Search Available Version of Spesific Package on Debian Based OS $ apt list -a \u0026lt;package_name\u0026gt; Install Spesific Kubernetes Version $ sudo apt update;sudo apt install -qy kubelet=1.15.5-00 kubectl=1.15.5-00 kubeadm=1.15.5-00 Open Spesific Port on Centos 7 iptables -I INPUT 5 -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT Replace String Using Sed sed -i \u0026#39;s/old-string/new-string/g\u0026#39; Find and copy files find /var/cache/dnf -iname \u0026#34;*.rpm\u0026#34; -exec cp {} packages/ \\; Encrypt secret envar value using Google KMS echo -n \u0026#34;This is my secret\u0026#34; | gcloud kms encrypt --plaintext-file=- --ciphertext-file=- --location=global --keyring=mykeyring --key=myappkey | base64 -w 0 Encrypt file using Google KMS gcloud kms encrypt \\ --key myappkey \\ --keyring mykeyring \\ --location global \\ --plaintext-file application.properties \\ --ciphertext-file application.properties.enc Check DNS record $ dig +noall +answer google.com google.com.\t204\tIN\tA\t74.125.24.102 google.com.\t204\tIN\tA\t74.125.24.138 google.com.\t204\tIN\tA\t74.125.24.139 google.com.\t204\tIN\tA\t74.125.24.101 google.com.\t204\tIN\tA\t74.125.24.100 google.com.\t204\tIN\tA\t74.125.24.113 Check service port $ getent services 53 domain 53/tcp Troubleshoot SELinux Issue on RHEL/CentOS # 1. Find your error from journalctl or audit.log then get the audit ID. # 2. Analyze grep 1624284378.419:2066 /var/log/audit/audit.log |audit2why Replace multiple file on OSX find /to/my/path -type f -name \u0026#34;*.yaml\u0026#34; -exec sed -i \u0026#39;\u0026#39; -e \u0026#39;s/halo.com/hai.id/g\u0026#39; {} \\; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://www.rahmatawe.com/notes/sysadmin/bash/","summary":"Rsync $ rsync -avzhe \u0026#39;ssh -p [port_number]\u0026#39; -P [user@remote_ip]:/path/to/file/source /path/to/file/destination Scan IP on Network $ nmap -sP [ip_address/prefix] Search Available Version of Spesific Package on Debian Based OS $ apt list -a \u0026lt;package_name\u0026gt; Install Spesific Kubernetes Version $ sudo apt update;sudo apt install -qy kubelet=1.15.5-00 kubectl=1.15.5-00 kubeadm=1.15.5-00 Open Spesific Port on Centos 7 iptables -I INPUT 5 -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT Replace String Using Sed sed -i \u0026#39;s/old-string/new-string/g\u0026#39; Find and copy files find /var/cache/dnf -iname \u0026#34;*.","tags":null,"title":"Bash Linux"},{"categories":null,"contents":" Generate Kubernetes secret and configmap YAML manifest # Secret kubectl create secret generic my-config --from-file=configuration/ -o yaml --dry-run # Configmap kubectl create configmap my-config --from-file=configuration/ -o yaml --dry-run Generate docker credential secret for Kubernetes kubectl create -n registry secret docker-registry registry-auth-dockerconfig-secret --docker-server=registry.rahmatawe.com --docker-username=[YOUR_USERNAME] --docker-password=[YOUR_REGISTRY_PASSWORD] --dry-run=client -oyaml Running short-lived container to compile source code $ sudo docker run --rm -it -v ${PWD}:/app -w /app openjdk:11-jdk-slim /bin/sh -c ./gradlew buildRun ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://www.rahmatawe.com/notes/sysadmin/container/","summary":" Generate Kubernetes secret and configmap YAML manifest # Secret kubectl create secret generic my-config --from-file=configuration/ -o yaml --dry-run # Configmap kubectl create configmap my-config --from-file=configuration/ -o yaml --dry-run Generate docker credential secret for Kubernetes kubectl create -n registry secret docker-registry registry-auth-dockerconfig-secret --docker-server=registry.rahmatawe.com --docker-username=[YOUR_USERNAME] --docker-password=[YOUR_REGISTRY_PASSWORD] --dry-run=client -oyaml Running short-lived container to compile source code $ sudo docker run --rm -it -v ${PWD}:/app -w /app openjdk:11-jdk-slim /bin/sh -c ./gradlew buildRun ","tags":null,"title":"Container Linux"},{"categories":["devops"],"contents":"In this article I\u0026rsquo;ll explain my process of analyzing and setting up Prometheus, where I maybe effectively increase query performance and addressed challenges related to cardinality. FYI, I use this stack on my monitoring system: Grafana, Promethues, Thanos. The metrics itself gethered from several source: node exporter, kube-state-metrics, etc.\n1. List unused metrics Firs, we need to list metrcis that used in our Grafana. To do this task, we can use mimirtool.\n$ mimirtool analyze grafana --address=${GRAFANA_URL} --key=\u0026#34;${GRAFANA_API_TOKEN}\u0026#34; In my case, I execute this command:\n$ mimirtool analyze grafana --address=https://grafana.rahmatawe.com --key=\u0026#34;glsa_jLKvTx6RLkGXXXX6XKS6DXlrulepsy_xxxxx\u0026#34; Anw, you can get GRAFANA_API_TOKEN by creating service account on Grafana dashboard. Above command will generate file named metrics-in-grafana.json. Using this file, we will compare it to metrics stored in Prometheus.\n#port forward to prometheus $ kubectl port-forward prometheus-prometheus-0 9090:9090 -n monitoring # Compare grafana metrics and prometheus $ mimirtool analyze prometheus --grafana-metrics-file=\u0026#34;metrics-in-grafana.json\u0026#34; --address=http://localhost:9090 INFO[0002] 73815 active series are being used in dashboards INFO[0002] Found 2495 metric names INFO[0017] 434700 active series are NOT being used in dashboards INFO[0017] 467 in use active series metric count INFO[0017] 2028 not in use active series metric count NOTE: Adjust prometheus-prometheus-0 with your prometheus pod name and monitoring with namespace where your prometheus pod deployed.\nIt will generate file prometheus-metrics.json. Sort it.\n$ jq -r \u0026#34;.in_use_metric_counts[].metric\u0026#34; prometheus-metrics.json | sort \u0026gt; used_metrics.txt $ jq -r \u0026#34;.additional_metric_counts[].metric\u0026#34; prometheus-metrics.json | sort \u0026gt; unused_metrics.txt 2. Drop unused metrics On step 1, we have been list used metrics and unused metrics. Next step, we will check metrics which have high cardinality via Prometheus dashboard http://localhost:9090/tsdb-status. Hmm, let us check metrics apiserver_request_duration_seconds_bucket.\n$ grep apiserver_request_duration_seconds_bucket u*_metrics.txt unused_metrics.txt:apiserver_request_duration_seconds_bucket We can drop this metrics since it\u0026rsquo;s not used by Grafana. I will drop it via its ServiceMonitor. You can drop it other method (ex: prometheus config directly) depend on your setup.\n--- apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: kube-apiserver namespace: monitoring labels: prometheus: main release: prometheus-operator ... metricRelabelings: - sourceLabels: [\u0026#34;__name__\u0026#34;] regex: \u0026#39;apiserver_request_duration_seconds_bucket\u0026#39; action: drop That\u0026rsquo;s it. Simple task to drop your bloated Prometheus metrics. Bye!\nRef:\nhttps://medium.com/@dotdc/prometheus-performance-and-cardinality-in-practice-74d5d9cd6230 https://www.robustperception.io/dropping-metrics-at-scrape-time-with-prometheus/ ","date":"December 1, 2022","hero":"/posts/tidy-up-prometheus/imgs/title.png","permalink":"https://www.rahmatawe.com/posts/tidy-up-prometheus/","summary":"In this article I\u0026rsquo;ll explain my process of analyzing and setting up Prometheus, where I maybe effectively increase query performance and addressed challenges related to cardinality. FYI, I use this stack on my monitoring system: Grafana, Promethues, Thanos. The metrics itself gethered from several source: node exporter, kube-state-metrics, etc.\n1. List unused metrics Firs, we need to list metrcis that used in our Grafana. To do this task, we can use mimirtool.","tags":["linux","monitoring"],"title":"Tidy up our Prometheus metrics!"},{"categories":["devops"],"contents":"It\u0026rsquo;s just PoC of collecting Windows logs using open source project such as Promtail, Loki and Grafana.\nEnvironment # Servers ag-rh2 : 10.54.54.6 (Grafana + Loki) win2k19 : 10.54.54.219 (Promtail) # OS Packages Release RHEL 8.4 Windows Server 2019 Loki 2.5 Grafana 8.4.6 Setup Loki 1. Download package Loki curl -O -L \u0026#34;https://github.com/grafana/loki/releases/download/v2.5.0/loki-linux-amd64.zip\u0026#34; 2. Setup loki binary # Unzip package unzip loki-linux-amd64.zip # Grant execute permission chmod +x loki-linux-amd64 # Create directory for loki installation sudo mkdir -p /opt/loki/{bin,conf,data} # Move loki binary mv loki-linux-amd64 /opt/loki/bin/loki 3. Setup loki configuration Default configuration can be retrieved from here. I create loki config on /opt/loki/config/loki-local-config.yaml using below content:\nauth_enabled: false server: http_listen_port: 3100 ingester: lifecycler: address: 127.0.0.1 ring: kvstore: store: inmemory replication_factor: 1 final_sleep: 0s chunk_idle_period: 1h # Any chunk not receiving new logs in this time will be flushed max_chunk_age: 1h # All chunks will be flushed when they hit this age, default is 1h chunk_target_size: 1048576 # Loki will attempt to build chunks up to 1.5MB, flushing first if chunk_idle_period or max_chunk_age is reached first chunk_retain_period: 30s # Must be greater than index read cache TTL if using an index cache (Default index read cache TTL is 5m) max_transfer_retries: 0 # Chunk transfers disabled wal: dir: /opt/loki/data/wal schema_config: configs: - from: 2020-10-24 store: boltdb-shipper object_store: filesystem schema: v11 index: prefix: index_ period: 24h storage_config: boltdb_shipper: active_index_directory: /opt/loki/data/boltdb-shipper-active cache_location: /opt/loki/data/boltdb-shipper-cache cache_ttl: 24h # Can be increased for faster performance over longer query periods, uses more disk space shared_store: filesystem filesystem: directory: /opt/loki/data/chunks compactor: working_directory: /opt/loki/data/boltdb-shipper-compactor shared_store: filesystem compaction_interval: 10m retention_enabled: true retention_delete_delay: 2h retention_delete_worker_count: 150 limits_config: reject_old_samples: true reject_old_samples_max_age: 168h chunk_store_config: max_look_back_period: 0s table_manager: retention_deletes_enabled: true retention_period: 30d ruler: storage: type: local local: directory: /opt/loki/data/rules rule_path: /opt/loki/data/rules-temp alertmanager_url: http://localhost:9093 ring: kvstore: store: inmemory enable_api: true analytics: reporting_enabled: false On above configuration, there is configuration for alertmanager but we will not include alertmanager installation in this post.\n4. Create system user for loki sudo useradd --system loki 5. Change permission on loki directory # Change ownership sudo chown -R loki:loki /opt/loki # Restore SELinux label sudo restorecon -vRF /opt/loki/ 6. Run loki service on systemd First, create systemd file for loki on /etc/systemd/system/loki.service. Paste below content.\n[Unit] Description=Loki service After=network.target [Service] Type=simple User=loki ExecStart=/opt/loki/bin/loki -config.file /opt/loki/conf/loki-local-config.yaml Restart=always [Install] WantedBy=multi-user.target Then, run loki service.\nsudo systemctl enable --now loki.service 7. Open port for loki service sudo firewall-cmd --add-port 3100/tcp --permanent sudo firewall-cmd --reload Setup Grafana 1. Download Grafana RPM package curl -O -L https://dl.grafana.com/oss/release/grafana-8.4.6-1.x86_64.rpm 2. Install package sudo yum localinstall grafana-8.4.6-1.x86_64.rpm 3. Start grafana service sudo systemctl enable --now grafana-server.service 4. Open port for grafana service sudo firewall-cmd --add-port 3000/tcp --permanent sudo firewall-cmd --reload 5. Add Loki datasource to Grafana. Open grafana URL on 10.54.54.6:3000 then add Loki as datasource. Setup Promtail 1. Download promtail binary To collect log from vent Viewer on Windows Server, we need to setup promtail. Binary file can be downloaded in here. Move the exctracted file to C:\\Program Files\\promtail, see below for detail. For new installation, it should be contain only the binary file promtail-windows-amd64.exe.\n2. Create promtail configuration Create promtail configuration file promtail-local-config.yaml with following content.\nserver: http_listen_port: 9080 grpc_listen_port: 0 clients: - url: http://10.54.54.6:3100/loki/api/v1/push scrape_configs: - job_name: windows-application windows_events: eventlog_name: \u0026#34;Application\u0026#34; xpath_query: \u0026#34;*[System[(Level=1 or Level=2 or Level=3)]]\u0026#34; # Critical, Error, Warning labels: logsource: windows-eventlog use_incoming_timestamp: true bookmark_path: \u0026#34;./bookmark-application.xml\u0026#34; exclude_event_data: true pipeline_stages: - json: expressions: level: levelText - labels: level: relabel_configs: - source_labels: [\u0026#39;computer\u0026#39;] target_label: \u0026#39;host\u0026#39; - job_name: windows-security windows_events: eventlog_name: \u0026#34;Security\u0026#34; xpath_query: \u0026#34;*[System[(Level=1 or Level=2 or Level=3)]]\u0026#34; labels: logsource: windows-eventlog use_incoming_timestamp: true bookmark_path: \u0026#34;./bookmark-security.xml\u0026#34; exclude_event_data: true exclude_user_data: true pipeline_stages: - json: expressions: level: levelText - labels: level: relabel_configs: - source_labels: [\u0026#39;computer\u0026#39;] target_label: \u0026#39;host\u0026#39; - job_name: windows-system windows_events: eventlog_name: \u0026#34;System\u0026#34; xpath_query: \u0026#34;*[System[(Level=1 or Level=2 or Level=3)]]\u0026#34; labels: logsource: windows-eventlog use_incoming_timestamp: true bookmark_path: \u0026#34;./bookmark-system.xml\u0026#34; exclude_event_data: true exclude_user_data: true pipeline_stages: - json: expressions: level: levelText - labels: level: relabel_configs: - source_labels: [\u0026#39;computer\u0026#39;] target_label: \u0026#39;host\u0026#39; 3. Test promtail Test the configuration by running promtail directly via Powershell. Use Ctrl+C to stop program.\n\u0026amp; \u0026#39;C:\\Program Files\\promtail\\promtail-windows-amd64.exe\u0026#39; --config.file=\u0026#39;C:\\Program Files\\promtail\\promtail-local-config.yaml\u0026#39; 4. Run promtail using windows service wrapper. There are some service wrapper on Windows, for example: sc.exe, nssm.exe and winsw. Windows has built in service wrapper: sc.exe, but when I use sc.exe to run promtail it always return error: StartService FAILED 1053. I\u0026rsquo;m not really familiar with Windows Server, so still figuring out why this error appear. So, I use nssm to wrap my promtail. You only need to download, unzip it and run below command.\n.\\nssm.exe install promtail Boom, GUI windows will appear. Set the setting like below. You can also bypass the GUI, with .\\nssm install \u0026lt;servicename\u0026gt; \u0026lt;application\u0026gt; [\u0026lt;options\u0026gt;].\nAfter service created, configure log file.\n.\\nssm.exe set promtail AppStderr \u0026#39;C:\\Program Files\\promtail\\promtail-error.log\u0026#39; .\\nssm.exe set promtail AppStdout \u0026#39;C:\\Program Files\\promtail\\promtail.log\u0026#39; Then, start the service.\n.\\nssm.exe start promtail 5. Open Grafana to check incoming logs References:\nGrafana Loki Storage Retention\nLog Scrapping made Easy with Grafana Loki in Windows\nPromtail Scraping (Service Discovery)\nStages\n","date":"April 15, 2022","hero":"/posts/send-event-viewer-log-to-grafana-loki/imgs/title.png","permalink":"https://www.rahmatawe.com/posts/send-event-viewer-log-to-grafana-loki/","summary":"It\u0026rsquo;s just PoC of collecting Windows logs using open source project such as Promtail, Loki and Grafana.\nEnvironment # Servers ag-rh2 : 10.54.54.6 (Grafana + Loki) win2k19 : 10.54.54.219 (Promtail) # OS Packages Release RHEL 8.4 Windows Server 2019 Loki 2.5 Grafana 8.4.6 Setup Loki 1. Download package Loki curl -O -L \u0026#34;https://github.com/grafana/loki/releases/download/v2.5.0/loki-linux-amd64.zip\u0026#34; 2. Setup loki binary # Unzip package unzip loki-linux-amd64.zip # Grant execute permission chmod +x loki-linux-amd64 # Create directory for loki installation sudo mkdir -p /opt/loki/{bin,conf,data} # Move loki binary mv loki-linux-amd64 /opt/loki/bin/loki 3.","tags":["linux","monitoring"],"title":"Send Log from Event Viewer on Windows Server 2019 to Grafana Loki"}]