<!DOCTYPE html>
<html lang="en-us"><head>
  <title>RahmatAwe</title>

<meta name="theme-color" content="" />
<meta charset="utf-8" />
<meta content="width=device-width, initial-scale=1.0" name="viewport" />
<meta name="description" content="Living, Working, Sleeping" />
<meta name="author" content="Rahmat Agung Wibowo" />
<meta name="generator" content="aafu theme by Darshan in Hugo 0.74.3" />

        <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">        <link rel="manifest" href="/site.webmanifest">        <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#252627">        <link rel="shortcut icon" href="/favicon.ico">        

  <link
    rel="stylesheet"
    href="/css/bootstrap/bootstrap.min.css"
  />
  <link
    rel="stylesheet"
    href="https://use.fontawesome.com/releases/v5.5.0/css/all.css"
    integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU"
    crossorigin="anonymous"
  />
  <link
    rel="stylesheet"
    href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"
  />
  <link
    rel="stylesheet"
    href="//fonts.googleapis.com/css?family=Didact+Gothic%7CRoboto:400%7CRoboto+Mono"
  />
  <link rel="stylesheet" href="/css/aafu_light.css" />
  <link rel="stylesheet" href="/css/aafu.css" />

  <script>
    var themeColor = document.querySelector("meta[name=theme-color]");
    window.onload = () => {
      themeColor.content = getComputedStyle(document.body)["background-color"];
      let defaultActivePanel = document.querySelector(".accordion.active");
      if (defaultActivePanel) {
        defaultActivePanel.nextElementSibling.style.maxHeight =
          defaultActivePanel.nextElementSibling.scrollHeight + "px";
      }
    };
    window.onresize = () => {
      let defaultActivePanel = document.querySelector(".accordion.active");
      if (defaultActivePanel) {
        defaultActivePanel.nextElementSibling.style.maxHeight =
          defaultActivePanel.nextElementSibling.scrollHeight + "px";
      }
    };
  </script>
</head>
<body class="container">
    <main style="min-height: calc(100vh - 60px);">
      
      <div class="d-flex flex-row row p-2">
  <h3 class="main-menu mr-3">
    <a href="https://riupie.github.com/">Home</a>
  </h3>
  <h3 class="main-menu mr-3">
    <a href="/blog">Blog</a>
  </h3>
  <h3 class="main-menu mr-3">
    <a href="/categories">Categories</a>
  </h3>
</div>

      
<div class="rounded p-2 aafu-border border">
  <div class="border-bottom aafu-border">
    <h1 class="top-h1" style="font-size: 2.75em;">Deploying HCI Openstack using Kolla Ansible</h1><div class="mb-2">
  <p class="mb-1">October 17, 2020</p>
   
  
  <p class="metadata-value mb-1 taxa taxa-container-div list-categories">
    Categories: 
    <a
      class="pl-1 pr-1 rounded border border-secondary"
      href="/categories/cloud"
      title="categories"
    >cloud</a>
    
  </p>
  
  
  
  
  
  <p class="metadata-value mb-1 taxa taxa-container-div list-tags">
    Tags: 
    <a
      class="pl-1 pr-1 rounded border border-secondary"
      href="/tags/linux"
      title="tags"
    >linux</a>
    
    <a
      class="pl-1 pr-1 rounded border border-secondary"
      href="/tags/openstack"
      title="tags"
    >openstack</a>
    
    <a
      class="pl-1 pr-1 rounded border border-secondary"
      href="/tags/ceph"
      title="tags"
    >ceph</a>
    
  </p>
  
  
</div>
</div>
  <div class="content">
    <img src=imgs/2020-os_topology.png>
<h3 id="ip-information">IP Information</h3>
<table class="table table-striped">
<tbody>
<tr>
<td><strong>Hostname</strong></td>
<td><strong>Storage Interface (enp1s0)</strong></td>
<td><strong>Openstack Interface (enp7s0)</strong></td>
</tr>
<tr>
<td>server0</td>
<td>10.50.50.10</td>
<td>10.51.51.10</td>
</tr>
<tr>
<td>server1</td>
<td>10.50.50.11</td>
<td>10.51.51.11</td>
</tr>
<tr>
<td>server2</td>
<td>10.50.50.12</td>
<td>10.51.51.12</td>
</tr>
</tbody>
</table>
</br>
<h1 id="a-deploy-ceph-cluster">A. Deploy Ceph Cluster</h1>
<p>In this first stage, I will deploy Ceph Cluster using Ceph Ansible. Ceph Ansible has two different approach when deploy Ceph Cluster: 1) Systemd based and 2) Container based. In here, I will use container based deployment which is use Podman as container runtime.</p>
<h3 id="1-install-required-packages">1. Install required packages</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">yum install git python3-pip vim -y
pip3 install ansible
</code></pre></div><h3 id="2-clone-ceph-ansible">2. Clone Ceph Ansible</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">git clone https://github.com/ceph/ceph-ansible
cd ceph-ansible
git checkout stable-5.0
</code></pre></div><h3 id="3-copy-required-files">3. Copy required files</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cp site-container.yml.sample site-container.yml
cp group_vars/all.yml.sample group_vars/all.yml
cp group_vars/osds.yml.sample group_vars/osds.yml
</code></pre></div><h3 id="4-create-inventory">4. Create inventory</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vim inventory 
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">[mons]
<span style="color:#ae81ff">10.50.50.1</span>[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">2</span>]

[mgrs]
<span style="color:#ae81ff">10.50.50.1</span>[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">2</span>]

[grafana-server]
<span style="color:#ae81ff">10.50.50.10</span>

[osds]
<span style="color:#ae81ff">10.50.50.1</span>[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">2</span>]

[mdss]
<span style="color:#ae81ff">10.50.50.10</span>

[clients]
<span style="color:#ae81ff">10.50.50.10</span>
</code></pre></div><h3 id="5-configure-ceph-ansible-variable">5. Configure ceph ansible variable</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vim group_vars/all.yml
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#66d9ef">ceph_origin</span>: repository
<span style="color:#66d9ef">ceph_repository</span>: community
<span style="color:#66d9ef">ceph_repository_type</span>: cdn
<span style="color:#66d9ef">ceph_stable_release</span>: octopus
<span style="color:#66d9ef">containerized_deployment</span>: <span style="color:#66d9ef">true</span>
<span style="color:#66d9ef">ceph_docker_image</span>: ceph/daemon
<span style="color:#66d9ef">ceph_docker_image_tag</span>: latest-octopus
<span style="color:#66d9ef">ceph_docker_registry</span>: docker.io

<span style="color:#66d9ef">copy_admin_key</span>: True
<span style="color:#66d9ef">cephx</span>: <span style="color:#66d9ef">true</span>

<span style="color:#66d9ef">public_network</span>: <span style="color:#ae81ff">10.50.50.0</span>/<span style="color:#ae81ff">24</span>
<span style="color:#66d9ef">cluster_network</span>: <span style="color:#ae81ff">10.50.50.0</span>/<span style="color:#ae81ff">24</span>
<span style="color:#66d9ef">monitor_interface</span>: enp1s0
<span style="color:#66d9ef">dashboard_admin_password</span>: yasmin88
<span style="color:#66d9ef">grafana_admin_password</span>: yasmin88
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vim group_vars/osds.yml
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#66d9ef">osd_objectstore</span>: bluestore
<span style="color:#66d9ef">devices</span>:
  - /dev/vdb
  - /dev/vdc
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vim site-container.yml
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">...
- <span style="color:#66d9ef">hosts</span>:
  - mons
  - osds
  - mdss
  - clients
  - mgrs
  - grafana-server
...

</code></pre></div><h3 id="6-deploy-containerized-ceph-cluster">6. Deploy containerized ceph cluster</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">ansible-playbook -i inventory site-container.yml
</code></pre></div><h3 id="7-install-epel-release-and-ceph-client-on-each-node">7. Install epel-release and ceph client on each node</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">yum install epel-release -y
rpm -ivh https://download.ceph.com/rpm-octopus/el8/noarch/ceph-release-1-1.el8.noarch.rpm
yum install ceph-common -y
</code></pre></div><h3 id="8-verify-ceph-cluster">8. Verify Ceph Cluster</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ ceph -s

  cluster:
    id:     b9a5eeab-b69a-4779-a990-fd76d7856205
    health: HEALTH_OK
 
  services:
    mon: <span style="color:#ae81ff">3</span> daemons, quorum server0,server1,server2 <span style="color:#f92672">(</span>age 27h<span style="color:#f92672">)</span>
    mgr: server1<span style="color:#f92672">(</span>active, since 8d<span style="color:#f92672">)</span>, standbys: server2, server0
    mds: cephfs:1 <span style="color:#f92672">{</span>0<span style="color:#f92672">=</span>server0<span style="color:#f92672">=</span>up:active<span style="color:#f92672">}</span>
    osd: <span style="color:#ae81ff">6</span> osds: <span style="color:#ae81ff">6</span> up <span style="color:#f92672">(</span>since 8d<span style="color:#f92672">)</span>, <span style="color:#ae81ff">6</span> in <span style="color:#f92672">(</span>since 8d<span style="color:#f92672">)</span>
 
  task status:
    scrub status:
        mds.server0: idle
 
  data:
    pools:   <span style="color:#ae81ff">7</span> pools, <span style="color:#ae81ff">145</span> pgs
    objects: <span style="color:#ae81ff">972</span> objects, 3.1 GiB
    usage:   <span style="color:#ae81ff">134</span> GiB used, <span style="color:#ae81ff">226</span> GiB / <span style="color:#ae81ff">360</span> GiB avail
    pgs:     <span style="color:#ae81ff">145</span> active+clean
</code></pre></div><h1 id="b-create-ceph-pool-and-client-for-openstack">B. Create Ceph Pool and Client for Openstack</h1>
<h3 id="1-create-openstack-pool">1. Create Openstack pool</h3>
<pre><code>ceph osd pool create volumes
ceph osd pool create images
ceph osd pool create backups
ceph osd pool create vms

rbd pool init volumes
rbd pool init images
rbd pool init backups
rbd pool init vms
</code></pre><h3 id="2-share-ceph-config-to-each-server">2. Share ceph config to each server</h3>
<pre><code>ssh 10.50.50.11 sudo tee /etc/ceph/ceph.conf &lt;/etc/ceph/ceph.conf
ssh 10.50.50.12 sudo tee /etc/ceph/ceph.conf &lt;/etc/ceph/ceph.conf
</code></pre><h3 id="3-setup-client-configuration">3. Setup Client Configuration</h3>
<pre><code>ceph auth get-or-create client.glance mon 'profile rbd' osd 'profile rbd pool=images' mgr 'profile rbd pool=images'
ceph auth get-or-create client.cinder mon 'profile rbd' osd 'profile rbd pool=volumes, profile rbd pool=vms, profile rbd-read-only pool=images' mgr 'profile rbd pool=volumes, profile rbd pool=vms'
ceph auth get-or-create client.cinder-backup mon 'profile rbd' osd 'profile rbd pool=backups' mgr 'profile rbd pool=backups'
</code></pre><h3 id="4-setup-ceph-client">4. Setup Ceph Client</h3>
<pre><code>ceph auth get-or-create client.glance | ssh 10.50.50.10 sudo tee /etc/ceph/ceph.client.glance.keyring
ceph auth get-or-create client.cinder | ssh 10.50.50.10 sudo tee /etc/ceph/ceph.client.cinder.keyring
ceph auth get-or-create client.cinder-backup | ssh 10.50.50.10 sudo tee /etc/ceph/ceph.client.cinder-backup.keyring

ceph auth get-or-create client.glance | ssh 10.50.50.11 sudo tee /etc/ceph/ceph.client.glance.keyring
ceph auth get-or-create client.cinder | ssh 10.50.50.11 sudo tee /etc/ceph/ceph.client.cinder.keyring
ceph auth get-or-create client.cinder-backup | ssh 10.50.50.11 sudo tee /etc/ceph/ceph.client.cinder-backup.keyring

ceph auth get-or-create client.glance | ssh 10.50.50.12 sudo tee /etc/ceph/ceph.client.glance.keyring
ceph auth get-or-create client.cinder | ssh 10.50.50.12 sudo tee /etc/ceph/ceph.client.cinder.keyring
ceph auth get-or-create client.cinder-backup | ssh 10.50.50.12 sudo tee /etc/ceph/ceph.client.cinder-backup.keyring
</code></pre><h3 id="5-verify-ceph-pool-list">5. Verify Ceph Pool List</h3>
<pre><code>$ ceph osd lspools

1 device_health_metrics
2 cephfs_data
3 cephfs_metadata
6 volumes
7 images
8 backups
9 vms
</code></pre><h1 id="openstack-cluster-deployment">Openstack Cluster Deployment</h1>
<h3 id="0-preflight">0. Preflight</h3>
<p>Ensure each server could be accessed without password. If not, create ssh keypair then share its public key to each servers. I do this from server0.</p>
<pre><code>ssh-keygen
</code></pre><p>After keypair is generated, copy its public key to server0,server1 and server2.</p>
<pre><code>ssh-copy-id root@server0
ssh-copy-id root@server1
ssh-copy-id root@server2

</code></pre><h3 id="1-install-kolla-ansible">1. Install kolla ansible</h3>
<pre><code>pip3 install kolla-ansible==10.0
</code></pre><h3 id="2-create-kolla-directory">2. Create kolla directory</h3>
<pre><code>mkdir /etc/kolla
</code></pre><h3 id="3-copy-configuration-to-kolla-directory">3. Copy configuration to kolla directory</h3>
<pre><code>cp -r /usr/local/share/kolla-ansible/etc_examples/kolla/* /etc/kolla/
</code></pre><h3 id="4-setup-ansiblecfg">4. Setup ansible.cfg</h3>
<pre><code>mkdir /etc/ansible
vim /etc/ansible/ansible.cfg
</code></pre><pre><code>[defaults]
host_key_checking=False
pipelining=True
forks=100
</code></pre><h3 id="5-setup-inventory">5. Setup inventory</h3>
<pre><code>cd
/usr/local/share/kolla-ansible/ansible/inventory/multinode .
vim multinode
</code></pre><pre><code>[control]
server[0]

[network]
server[0]

[compute]
server[1:2]

[monitoring]
server[0:2]

[storage]
server[0:2]
</code></pre><h3 id="6-generate-openstack-services-password">6. Generate Openstack Services Password</h3>
<pre><code>kolla-genpwd
</code></pre><h3 id="7-setup-global-variables">7. Setup Global Variables</h3>
<p>In here, I use 2 VIP address for internal services access (10.51.51.100) and public access (10.51.51.101). Both of them should be on the same subnet. Parameter <code>neutron_external_interface</code> is used to define interface that will be used as provider network (for floating IP).</p>
<pre><code>vim /etc/kolla/globals.yml
</code></pre><pre><code>---
kolla_base_distro: &quot;centos&quot;
kolla_install_type: &quot;binary&quot;
openstack_release: &quot;ussury&quot;
kolla_internal_vip_address: &quot;10.51.51.100&quot;
kolla_external_vip_address: &quot;10.51.51.101&quot;
kolla_enable_tls_external: &quot;yes&quot;
storage_interface: &quot;enp1s0&quot;
network_interface: &quot;enp7s0&quot;
neutron_external_interface: &quot;enp8s0&quot;
neutron_plugin_agent: &quot;ovn&quot;
enable_openstack_core: &quot;yes&quot;
enable_cinder: &quot;yes&quot;
enable_haproxy: &quot;yes&quot;
enable_neutron_provider_networks: &quot;yes&quot;
nova_compute_virt_type: &quot;kvm&quot;


enable_ceph: &quot;no&quot;
glance_backend_ceph: &quot;yes&quot;
cinder_backend_ceph: &quot;yes&quot;
nova_backend_ceph: &quot;yes&quot;
</code></pre><h2 id="openstack-services-configuration">Openstack Services Configuration</h2>
<h3 id="1-create-glance-configuration-directory">1. Create Glance Configuration Directory</h3>
<pre><code>mkdir -p /etc/kolla/config/glance/
</code></pre><h3 id="2-copy-ceph-configuration-for-glance-to-kolla">2. Copy ceph configuration for glance to kolla</h3>
<pre><code>cp /etc/ceph/ceph.conf /etc/kolla/config/glance/
cp /etc/ceph/ceph.client.glance.keyring /etc/kolla/config/glance/
</code></pre><h3 id="3-create-cinder-configuration-directory">3. Create Cinder Configuration Directory</h3>
<pre><code>mkdir -p /etc/kolla/config/cinder/cinder-volume
mkdir /etc/kolla/config/cinder/cinder-backup
</code></pre><h3 id="4-copy-ceph-configuration-for-cinder-to-kolla">4. Copy ceph configuration for cinder to kolla</h3>
<pre><code>cp /etc/ceph/ceph.client.cinder.keyring /etc/kolla/config/cinder/cinder-volume/
cp /etc/ceph/ceph.client.cinder.keyring /etc/kolla/config/cinder/cinder-backup/
cp /etc/ceph/ceph.client.cinder-backup.keyring /etc/kolla/config/cinder/cinder-backup/
</code></pre><h3 id="5-create-nova-configuration-directory">5. Create Nova Configuration Directory</h3>
<pre><code>mkdir /etc/kolla/config/nova
</code></pre><h3 id="6-copy-ceph-configuration-for-nova-to-kolla">6. Copy ceph configuration for nova to kolla</h3>
<pre><code>cp /etc/ceph/ceph.conf /etc/kolla/config/nova/
cp /etc/ceph/ceph.client.cinder.keyring /etc/kolla/config/nova/
cp /etc/ceph/ceph.client.cinder.keyring /etc/kolla/config/nova/ceph.client.nova.keyring
</code></pre><h3 id="7-add-glance-configuration">7. Add Glance Configuration</h3>
<pre><code>vim /etc/kolla/config/glance/glance-api.conf
</code></pre><pre><code>[glance_store]
stores = rbd
default_store = rbd
rbd_store_pool = images
rbd_store_user = glance
rbd_store_ceph_conf = /etc/ceph/ceph.conf
</code></pre><h3 id="8-add-cinder-configuration">8. Add Cinder Configuration</h3>
<pre><code>cat /etc/kolla/passwords.yml |grep cinder_rbd_secret_uuid
vim /etc/kolla/config/cinder.conf
</code></pre><pre><code>[DEFAULT]
enabled_backends=rbd-1
backup_ceph_conf=/etc/ceph/ceph.conf
backup_ceph_user=cinder-backup
backup_ceph_chunk_size = 134217728
backup_ceph_pool=backups
backup_driver = cinder.backup.drivers.ceph.CephBackupDriver
backup_ceph_stripe_unit = 0
backup_ceph_stripe_count = 0
restore_discard_excess_bytes = true

[rbd-1]
rbd_ceph_conf=/etc/ceph/ceph.conf
rbd_user=cinder
backend_host=rbd:volumes
rbd_pool=volumes
volume_backend_name=rbd-1
volume_driver=cinder.volume.drivers.rbd.RBDDriver
rbd_secret_uuid = 3f2ee568-97a8-4416-9865-a4567aa69b53 #add here
</code></pre><h3 id="9-add-nova-configuration">9. Add nova configuration</h3>
<pre><code>vim /etc/kolla/config/nova.conf
</code></pre><pre><code>[libvirt]
images_rbd_pool=vms
images_type=rbd
images_rbd_ceph_conf=/etc/ceph/ceph.conf
rbd_user=cinder
</code></pre><h3 id="10-add-heat-configuration">10. Add Heat Configuration</h3>
<pre><code>vim /etc/kolla/config/heat.conf
</code></pre><pre><code>[DEFAULT]
heat_metadata_server_url = http://10.51.51.100:8000
heat_waitcondition_server_url = http://10.51.51.100:8000/v1/waitcondition
server_keystone_endpoint_type = internal

[clients]
insecure = true

[clients_cinder]
endpoint_type = internalURL
insecure = true

[clients_glance]
endpoint_type = internalURL
insecure = true

[clients_heat]
endpoint_type = internalURL
insecure = true
url = http://10.51.51.100:8004/v1/%(tenant_id)s

[clients_keystone]
endpoint_type = internalURL
insecure = true
auth_uri = http://10.51.51.100:5000

[clients_neutron]
endpoint_type = internalURL
insecure = true

[clients_nova]
endpoint_type = internalURL
insecure = true

[clients_octavia]
endpoint_type = internalURL
insecure = true
</code></pre><h3 id="11-add-neutron-configuration">11. Add neutron configuration</h3>
<pre><code>vim /etc/kolla/config/neutron.conf
</code></pre><pre><code>[DEFAULT]
core_plugin = neutron.plugins.ml2.plugin.Ml2Plugin
service_plugins=trunk,ovn-router
router_scheduler_driver=neutron.scheduler.l3_agent_scheduler.ChanceScheduler
notify_nova_on_port_status_changes=True
notify_nova_on_port_data_changes=True
</code></pre><pre><code>mkdir /etc/kolla/config/neutron
vim /etc/kolla/config/neutron/ml2_conf.ini
</code></pre><pre><code>[ml2]
mechanism_drivers = ovn

[securitygroup]
enable_security_group=True
firewall_driver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
</code></pre><h3 id="12-generate-self-signed-certificate-for-openstack">12. Generate Self Signed Certificate for Openstack</h3>
<pre><code>kolla-ansible -i multinode certificates
</code></pre><h3 id="13-deployment-openstack">13. Deployment OpenStack</h3>
<pre><code>kolla-ansible -i multinode bootstrap-servers
kolla-ansible -i multinode prechecks
kolla-ansible -i multinode deploy
kolla-ansible -i multinode post-deploy
</code></pre><h3 id="18-testing-fungsional">18. Testing Fungsional</h3>
<p>It is a script that will create private network,public network, cirros image, and flavors. You can download it in <a href="https://gist.github.com/riupie/0fa2f94707c1a61cab85d15b7673deab">here</a>.</p>
<pre><code>./init-runonce
</code></pre>
  </div>
</div>
<div class="d-flex flex-row justify-content-center">
  <h3 class="mb-1 mt-1 text-left mr-4">
    
    <a
      href="/blog/deploying-upi-okd/"
      title="Deploying UPI OKD 4.5 Cluster"
    >
      <i class="nav-menu fas fa-chevron-circle-left"></i>
    </a>
    
  </h3>
  <h3 class="mb-1 mt-1 text-left ml-4">
    
    <a
      href="/blog/ldap-kubernetes-integration/"
      title="Implementing LDAP Authentication for Kubernetes using Dex on Ubuntu 18.04"
    >
      <i class="nav-menu fas fa-chevron-circle-right"></i>
    </a>
    
  </h3>
</div>


    </main>
    
    <footer class=" mt-2 mb-4 text-center ">
  <span class="markdownify">2020</span>
  <span >
    &middot;
    <i>
      <a href="https://rahmatawe.com">
        Rahmat Agung W
      </a>
    </i>
  </span>
</footer>

    
  </body>
</html>
